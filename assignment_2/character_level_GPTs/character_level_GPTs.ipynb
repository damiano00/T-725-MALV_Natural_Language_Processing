{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.1.0+cu121\n",
      "Is CUDA enabled? True\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "author: Damiano Pasquini\n",
    "date: 10/13/2023\n",
    "'''\n",
    "\n",
    "import torch\n",
    "import subprocess\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import transformers\n",
    "import datasets\n",
    "import tiktoken\n",
    "import wandb\n",
    "import tqdm\n",
    "\n",
    "# Check if CUDA (GPU support) is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tensor_on_device = torch.randn(3, 3).to(device)\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"Is CUDA enabled?\", torch.cuda.is_available())\n",
    "\n",
    "corpus = \"./nanoGPT/data/utterances.jsonl\"\n",
    "corpus_preprocessed = \"./nanoGPT/data/movies_text_preprocessed.txt\"\n",
    "# cli commands\n",
    "prepare = \"python data/shakespeare_char/prepare.py\"\n",
    "sample = \"python sample.py --out_dir=out-shakespeare-char --device=cpu\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T18:46:44.743807700Z",
     "start_time": "2023-10-10T18:46:44.735177700Z"
    }
   },
   "id": "f7659ca8a6d89f1f"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999982\n"
     ]
    }
   ],
   "source": [
    "def count_words(input=corpus):\n",
    "    words = subprocess.check_output(f\"wsl wc -w {input}\", shell=True)\n",
    "    return int(words.split()[0])\n",
    "\n",
    "print(count_words(corpus_preprocessed))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T19:27:41.205560800Z",
     "start_time": "2023-10-10T19:27:37.824789800Z"
    }
   },
   "id": "b61e662a13e743d5"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# run and print the output of the command\n",
    "def run_shell_cmd(cmd):\n",
    "    print(subprocess.check_output(cmd, shell=True).decode(\"utf-8\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T14:52:05.030365Z",
     "start_time": "2023-10-10T14:52:05.027788400Z"
    }
   },
   "id": "57a8d7a7c4315dc6"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "'./nanoGPT/data/movies_text_preprocessed.txt'"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_corpus(input=corpus, output=corpus_preprocessed):\n",
    "    # transform the jsonl file into a txt file, with the format \"speaker: text\". When the output file contains more than 1000000 words, stop. Divide the jsonl file into lines basing on the presence of \"id\":\n",
    "    with open(input, \"r\") as f:\n",
    "        text = f.read()\n",
    "    word_counter = 0\n",
    "    with open(output, \"w\") as f:\n",
    "        for line in text.replace(\"\\\\n\", \". \").split(\"\\n\"):\n",
    "            if word_counter > 1000000:\n",
    "                break\n",
    "            if line:\n",
    "                line = json.loads(line)\n",
    "                word_counter += len(line[\"text\"].split())+len(line[\"speaker\"].split())\n",
    "                f.write(f\"{line['speaker']}: {line['text']}\\n\")\n",
    "    return output\n",
    "\n",
    "preprocess_corpus(corpus)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T19:29:04.766454100Z",
     "start_time": "2023-10-10T19:29:00.800619300Z"
    }
   },
   "id": "125bf88cc2e79179"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# default training\n",
    "def train(eval_iters=20, log_interval=1, block_size=64, batch_size=12, n_layer=4, n_head=4, n_embd=128, max_iters=2000, lr_decay_iters=2000, dropout=0.0):\n",
    "    subprocess.run(f\"python train.py config/train_shakespeare_char.py --device=cpu --compile=False --eval_iters={eval_iters} --log_interval={log_interval} --block_size={block_size} --batch_size={batch_size} --n_layer={n_layer} --n_head={n_head} --n_embd={n_embd} --max_iters={max_iters} --lr_decay_iters={lr_decay_iters} --dropout={dropout}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T14:53:51.797963100Z",
     "start_time": "2023-10-10T14:53:51.795594Z"
    }
   },
   "id": "7803bbbd3b37f629"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prepare the data, train and sample from the model with the default parameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9ad0a2cfc9f62b29"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# default training\n",
    "print(\"Running prepare...\")\n",
    "run_shell_cmd(prepare)\n",
    "print(\"Training...\")\n",
    "train()\n",
    "print(\"Sampling...\")\n",
    "run_shell_cmd(sample)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4daa9cab6cebec7a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prepare the data, train and sample from the model with different configurations of hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "98040b64c242acaf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# train 1\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2667292034c5f2e1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# train 2\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da51b1079752dfcf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# train 3\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "114327239e954867"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading supreme-corpus to C:\\Users\\pasqu\\.convokit\\downloads\\supreme-corpus\n",
      "Downloading supreme-corpus from http://zissou.infosci.cornell.edu/convokit/datasets/supreme-corpus/supreme-corpus.zip (1255.8MB)... "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[23], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mconvokit\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Corpus, download\n\u001B[1;32m----> 2\u001B[0m corpus_2 \u001B[38;5;241m=\u001B[39m Corpus(filename\u001B[38;5;241m=\u001B[39m\u001B[43mdownload\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msupreme-corpus\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m)\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(corpus_2\u001B[38;5;241m.\u001B[39mget_utterance(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m2015_14_13.txt\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mtext)\n",
      "File \u001B[1;32m~\\PycharmProjects\\T_725_MALV_Natural_Language_Processing\\assignment_2\\venv\\Lib\\site-packages\\convokit\\util.py:171\u001B[0m, in \u001B[0;36mdownload\u001B[1;34m(name, verbose, data_dir, use_newest_version, use_local)\u001B[0m\n\u001B[0;32m    169\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    170\u001B[0m         url \u001B[38;5;241m=\u001B[39m DatasetURLs[name]\n\u001B[1;32m--> 171\u001B[0m         \u001B[43m_download_helper\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdownloadeds_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    172\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    173\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset already exists at \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(dataset_path))\n",
      "File \u001B[1;32m~\\PycharmProjects\\T_725_MALV_Natural_Language_Processing\\assignment_2\\venv\\Lib\\site-packages\\convokit\\util.py:255\u001B[0m, in \u001B[0;36m_download_helper\u001B[1;34m(dataset_path, url, verbose, name, downloadeds_path)\u001B[0m\n\u001B[0;32m    249\u001B[0m         length \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    250\u001B[0m             \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mround\u001B[39m(length \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m1e6\u001B[39m, \u001B[38;5;241m1\u001B[39m)) \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMB\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    251\u001B[0m             \u001B[38;5;28;01mif\u001B[39;00m length \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1e6\u001B[39m\n\u001B[0;32m    252\u001B[0m             \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mround\u001B[39m(length \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m1e3\u001B[39m, \u001B[38;5;241m1\u001B[39m)) \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mKB\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    253\u001B[0m         )\n\u001B[0;32m    254\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDownloading\u001B[39m\u001B[38;5;124m\"\u001B[39m, name, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfrom\u001B[39m\u001B[38;5;124m\"\u001B[39m, url, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m length \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m)...\u001B[39m\u001B[38;5;124m\"\u001B[39m, end\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m, flush\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m--> 255\u001B[0m     \u001B[43mshutil\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcopyfileobj\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresponse\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout_file\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    257\u001B[0m \u001B[38;5;66;03m# post-process (extract) corpora\u001B[39;00m\n\u001B[0;32m    258\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m name\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msubreddit\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\shutil.py:197\u001B[0m, in \u001B[0;36mcopyfileobj\u001B[1;34m(fsrc, fdst, length)\u001B[0m\n\u001B[0;32m    195\u001B[0m fdst_write \u001B[38;5;241m=\u001B[39m fdst\u001B[38;5;241m.\u001B[39mwrite\n\u001B[0;32m    196\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m--> 197\u001B[0m     buf \u001B[38;5;241m=\u001B[39m \u001B[43mfsrc_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlength\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    198\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m buf:\n\u001B[0;32m    199\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py:465\u001B[0m, in \u001B[0;36mHTTPResponse.read\u001B[1;34m(self, amt)\u001B[0m\n\u001B[0;32m    462\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlength \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m amt \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlength:\n\u001B[0;32m    463\u001B[0m     \u001B[38;5;66;03m# clip the read to the \"end of response\"\u001B[39;00m\n\u001B[0;32m    464\u001B[0m     amt \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlength\n\u001B[1;32m--> 465\u001B[0m s \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfp\u001B[38;5;241m.\u001B[39mread(amt)\n\u001B[0;32m    466\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m s \u001B[38;5;129;01mand\u001B[39;00m amt:\n\u001B[0;32m    467\u001B[0m     \u001B[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001B[39;00m\n\u001B[0;32m    468\u001B[0m     \u001B[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001B[39;00m\n\u001B[0;32m    469\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_close_conn()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\socket.py:706\u001B[0m, in \u001B[0;36mSocketIO.readinto\u001B[1;34m(self, b)\u001B[0m\n\u001B[0;32m    704\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m    705\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 706\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv_into\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    707\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[0;32m    708\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_timeout_occurred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\ssl.py:1278\u001B[0m, in \u001B[0;36mSSLSocket.recv_into\u001B[1;34m(self, buffer, nbytes, flags)\u001B[0m\n\u001B[0;32m   1274\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m flags \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m   1275\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1276\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m\n\u001B[0;32m   1277\u001B[0m           \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m)\n\u001B[1;32m-> 1278\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnbytes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1279\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1280\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\ssl.py:1134\u001B[0m, in \u001B[0;36mSSLSocket.read\u001B[1;34m(self, len, buffer)\u001B[0m\n\u001B[0;32m   1132\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1133\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m buffer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1134\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sslobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1135\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1136\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sslobj\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;28mlen\u001B[39m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# from convokit import Corpus, download\n",
    "# corpus_2 = Corpus(filename=download(\"supreme-corpus\"))\n",
    "# \n",
    "# print(corpus_2.get_utterance(\"2015_14_13.txt\").text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T17:55:09.362138100Z",
     "start_time": "2023-10-10T17:51:18.022425500Z"
    }
   },
   "id": "331fa7c0de41701"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
